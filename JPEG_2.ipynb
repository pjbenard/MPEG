{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format de compression MPEG\n",
    "\n",
    "## Etape 1 : coder une image en JPEG\n",
    "\n",
    "On va effectuer une quantification des coeffs. On n'implémente pas la compression JPEG mais on peut simuler la compression JPEG. On se contente de calculer la place théorique que prend l'image -> décomposition en bloc 8x8 -> transformée en cosinus discrets\n",
    "\n",
    "Librairies à utiliser : cv2, numpy et math\n",
    "\n",
    "JPEG = Joint Photographic Experts Group\n",
    "\n",
    "Le processus de compression JPEG comporte six étapes principales. On part de l'image brute :\n",
    "\n",
    "1. Transformation de couleurs\n",
    "2. Sous échantillonnage\n",
    "3. Découpage en blocs de pixels\n",
    "4. DCT\n",
    "5. Quantification\n",
    "6. Codage RLE et Huffman (on le fait pas nn?)\n",
    "\n",
    "Et on obtient une image compressée selon JPEG.\n",
    "\n",
    "Description des étapes :\n",
    "\n",
    "On distingue les basses et hautes freq : les basses constituent les données majeures présentes dans une image. Les hautes freq caractérisent les zones à fort contraste (changement brusques de couleur). Les hautes freq sont moins visibles, c'est dessus que la compression s'effectuera.\n",
    "\n",
    "- Quantification : là où se produite la majeure partie de la perte d'information et qui permet de gagner de la place. La quantification consiste à diviser cette mat de 8x8 (retournée par la DCT pour chaque bloc) par une matrice de quantification de 8x8 coeff choisis par le codeur. \n",
    "\n",
    "- Compression RLE et Huffman : le codage s'effectue en zigzag sur l'image. Ce résultat est compressé selon l'algorithme RLE (run length encoding, algo de compression sans pertes) basé sur la val 0 et un codage entropique de type Huffman (algo de compression sans perte basé sur un arbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réu du 4/11 :\n",
    "\n",
    "\n",
    "simuler un codage jpeg : prgm python à partir d'une image png on reproduit l'image comme si elle était codée en jpeg. on la découpe en 8x8, on fait un cos discret, on quantifie les coeff avec la table de quantification de jpeg estimation du poids qu'elle prendrait si elle était codée en jpeg\n",
    "\n",
    "calcul du poids : dépend de l'entropie des coefficients. l'entropie mesure la qtté d'info donné par les coeff\n",
    "on prend une suite, un prg python qui calcule l'entropie de la suite \n",
    "\n",
    "un prg python qui à pt d'une image fait le codage jpeg, renvoie l'image et un nb (l'entropie)\n",
    "\n",
    "pas de quantification qui soit pas trop petit\n",
    "interpolation binaire cubique par ex pour les rotations (déjà des codes python qui existent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codage compression JPEG :\n",
    "\n",
    "On importe les librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import cos, pi, sqrt\n",
    "from copy import deepcopy\n",
    "from typing import List\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation de l'image\n",
    "\n",
    "Rappel : Une image est généralement codée sur trois canaux de couleurs : Rouge, Vert, Bleu (RGB).\n",
    "Ainsi chaque pixel d'une image est défini par trois coefficients codés sur 8bits (le coefficient prend une valeur entre 0 et 255). Sans compression, une image de dimension 512x512 prend 512x512x8x3 = 6 291 456 bits = 786, 432 Ko.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "RGB\n",
      "(4608, 3456)\n"
     ]
    }
   ],
   "source": [
    "#Load the image\n",
    "img_RGB = Image.open('montagne.jpg')\n",
    "\n",
    "#Get basic details about the image\n",
    "print(img_RGB.format)\n",
    "print(img_RGB.mode)\n",
    "print(img_RGB.size)\n",
    "\n",
    "#show the image\n",
    "#plt.imshow(img_RGB)\n",
    "#ou \n",
    "img_RGB.show() #, qui ouvre une fenêtre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille de l'image ici est, d'après le lecteur d'image, de 23.8 MB.\n",
    "\n",
    "4608x 3456 x 8 x 3 = 381 791 232 bits = 47723,904 Ko\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Transformation des couleurs\n",
    "\n",
    "D'abort on va transformer les couleurs de l'image.\n",
    "Les codages de couleur type luminance/chrominance donnent les meilleurs taux de compression car oeil humain assez sensible à la luminosité (luminance) mais peu à la teinte (chrominance) d'une image. On fera donc un sous échantillonnage de couleurs sur ces couleurs là plutôt que sur RGB.\n",
    "\n",
    "![Perception](perception.png)\n",
    "\n",
    "La figure montre que la sensibilité de l'oeil humain est bien différente pour les couleurs rouge, vert et bleue constitutives de nos images. Ainsi le vert est-il le mieux perçu, puis vient le rouge, et enfin le bleu de maniere minoritaire. On passera donc d'une image codée en RGB à une image codée en fonction de sa luminance (Y), et de sa chrominance (Cb, Cr) (format YUV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer de couleurs RGB à YUV consiste à faire un changement de base orthogonale (Rappel : la base de RGB est orthogonale)\n",
    "\n",
    "En principe, on a en quelque sorte :\n",
    "\n",
    "  $$  Y ≃ R + G + B \\\\\n",
    "    U ≃ B – Y \\\\\n",
    "    V ≃ R – Y$$\n",
    "    \n",
    "La matrice de changement de base est plus particulièrement définie ainsi : (Wikipédia + autres sources)\n",
    "\n",
    "![changement](changement_base.png)\n",
    "\n",
    "Ici, on utilise simplement une fonction du module Image de la librairie PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_to_YUV(img):\n",
    "    img_YUV = img.convert('YCbCr')\n",
    "    return img_YUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_YUV = RGB_to_YUV(img_RGB)\n",
    "img_YUV.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sous échantillonnage des couleurs\n",
    "\n",
    "On doit donc en suite sous échantillonner les couleurs. On sépare les channels. On ne touche pas au channel Y mais on va rétrécir les image de U et V. Il y a plusieurs réglages possibles que l'on décrit avec la « notation J:a:b », définie ainsi, par bloc de 8x8 :\n",
    "- J est le nombre de pixels de Y conservés pour 4 pixels affichés, sur chaque ligne ;\n",
    "- a est le nombre de pixels de U conservés pour 4 pixels affichés, sur les lignes paires ;\n",
    "- b est le nombre de pixels de V conservés pour 4 pixels affichés, sur les lignes impaires.\n",
    "![subsampling](subsampling.png)\n",
    "\n",
    "Ainsi le sous échantillonnage de couleur le plus utilisé est le 4:2:0 (c'est à dire qu'on découpe l'image en bloc de 8x8). (Mais ce n'est pas le plus important, on peut prendre du 4:4:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Découpage en blocs\n",
    "\n",
    "En JPEG, on ne travaille pas sur une image entière : on travaille sur des blocs de 8x8 pixels (séparément en ce qui concerne l’intensité, le bleu et le rouge, donc).\n",
    "Si la taille d’une image n’est pas exactement un multiple de 8 dans un axe donné, et que\n",
    "la compression est forte, de légers défauts de compression pourraient apparaître. C’est un des soucis de JPEG.\n",
    "\n",
    "Chaque bloc de 8x8 est en suite envoyé pour être transformé par DCT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(img, block_width=8, block_height=8):\n",
    "    shape = img.shape\n",
    "    x_len = shape[0]//block_width\n",
    "    y_len = shape[1]//block_height\n",
    "    #print(x_len, y_len)\n",
    "    \n",
    "    chunks = []\n",
    "    x_indices = [i for i in range(0, shape[0]+1, block_width)]\n",
    "    y_indices = [i for i in range(0, shape[1]+1, block_height)]\n",
    "\n",
    "    shapes = list(zip(x_indices, y_indices))\n",
    "    \n",
    "    for i in range(len(shapes)):\n",
    "        try:\n",
    "            start_x = shapes[i][0]\n",
    "            start_y = shapes[i][1]\n",
    "            end_x = shapes[i+1][0]\n",
    "            end_y = shapes[i+1][1]\n",
    "            chunks.append( shapes[start_x:end_x][start_y:end_y] )\n",
    "        except IndexError:\n",
    "            print('End of Array')\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transformée en cosinus discret \n",
    "\n",
    "On fait une transformée DCT soit Discrete Cosine Transform. On applique cette transfo numérique à chaque bloc (variante de la transfo de fourier). Cette transfo décompose un bloc (considéré comme une fc num à deux variables) en une somme de fc cosinus oscillant à des freq différentes. Chaque bloc est ainsi décrit en une carte de freq et en amplitude plutôt qu'en puexels et coeff de couleur. (formule de la DCT dispo sur wiki) Le calcul d'une DCT est l'étape qui coûte le plus de temps et de ressources dans la compression JPE. Mais elle peremt de séparer les basses et hautes freq de l'image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    On part d'un tableau de valeurs y, x (ligne, colonne) et on en\n",
    "    renvoie un nouveau.\n",
    "\"\"\"\n",
    "\n",
    "def encoder_dct(ancien_tableau : List[List[int]]) -> List[List[int]]:\n",
    "    \n",
    "    # Le nouveau tableau aura le même nombre d'entrées (et de sous-\n",
    "    # entrées) que le tableau d'origine, mais pas les mêmes valeurs,\n",
    "    # c'est pourquoi on commence à copier le tableau d'origine (et\n",
    "    # ses tableaux imbriqués) pour en créer un distinct.\n",
    "    \n",
    "    nouveau_tableau : List[List[int]] = deepcopy(ancien_tableau)\n",
    "    \n",
    "    for nouveau_y in range(8):\n",
    "        for nouveau_x in range(8):\n",
    "            \n",
    "            nouvelle_valeur = 0\n",
    "            \n",
    "            for ancien_y in range(8):\n",
    "                for ancien_x in range(8):\n",
    "                    \n",
    "                    # Le cosinus retourne un facteur qui pondère\n",
    "                    # la valeur selon si on est dans la strie ou non.\n",
    "\n",
    "                    nouvelle_valeur += (\n",
    "                        ancien_tableau[ancien_y][ancien_x] *\n",
    "                        cos(((2 * ancien_y + 1) * nouveau_y * pi) / 16) *\n",
    "                        cos(((2 * ancien_x + 1) * nouveau_x * pi) / 16)\n",
    "                    )\n",
    "            \n",
    "            # Si on est au bord du tableau (aplat complet),\n",
    "            # cosinus retournera toujours 1 et le nombre\n",
    "            # pourrait être très gros : on va donc le\n",
    "            # réduire un peu\n",
    "            \n",
    "            if nouveau_y == 0:\n",
    "                nouvelle_valeur /= sqrt(2)\n",
    "            if nouveau_x == 0:\n",
    "                nouvelle_valeur /= sqrt(2)\n",
    "            nouvelle_valeur /= 4\n",
    "            \n",
    "            nouveau_tableau[nouveau_y][nouveau_x] = nouvelle_valeur\n",
    "    \n",
    "    return nouveau_tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources :\n",
    "\n",
    "http://www-ljk.imag.fr/membres/Valerie.Perrier/SiteWeb/node8.html\n",
    "\n",
    "https://fr.wikipedia.org/wiki/YUV\n",
    "\n",
    "https://compression.fiches-horaires.net/la-compression-avec-perte-1/le-compression-jpeg/\n",
    "\n",
    "https://github.com/QuantumNovice/ImageProcessing/blob/master/image_chunkify.py\n",
    "\n",
    "DCT :\n",
    "\n",
    "http://www-ljk.imag.fr/membres/Valerie.Perrier/SiteWeb/node9.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
