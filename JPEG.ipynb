{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pjbenard/MPEG/blob/main/JPEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format de compression MPEG\n",
    "\n",
    "Notre projet consiste en l'implémentation du format compression MPEG. \n",
    "Le projet est divisé en deux parties : la compression JPEG et le \"flot optique\".\n",
    "\n",
    "## I. Compression JPEG\n",
    "\n",
    "La compression JPEG (Joint Photographic Experts Group) est un processus qui permet de réduire la taille d'une image \n",
    "\n",
    "Le processus de compression comporte six étapes principales :\n",
    "\n",
    "1. Transformation de couleurs\n",
    "2. Sous échantillonnage\n",
    "3. Découpage en blocs de pixels\n",
    "4. DCT\n",
    "5. Quantification\n",
    "6. Codage RLE et Huffman \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "5Z93Pvk9wKY9",
    "outputId": "53e27bd0-e0ae-4ad3-9ff0-dee295492141"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.fftpack as fft\n",
    "\n",
    "#from bokeh.plotting import figure, show\n",
    "#from bokeh.io import output_notebook\n",
    "#import holoviews as hv\n",
    "#hv.config.enable_colab_support = True\n",
    "#hv.extension('bokeh')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement de l'image. On a le choix entre l'image 'RGB_illumination.jpg' ou 'montagne.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2xUurXoT2YW"
   },
   "outputs": [],
   "source": [
    "\n",
    "#img_url = \"https://upload.wikimedia.org/wikipedia/commons/2/28/RGB_illumination.jpg\"\n",
    "#response = requests.get(img_url)\n",
    "#img = np.array(Image.open(BytesIO(response.content))).astype(int)\n",
    "\n",
    "img = np.array(Image.open('images_notebook/montagne.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u9TVdRwUiWq",
    "outputId": "9cfaf777-bdf5-4453-eb89-5c2c2beee1a1"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de l'image et des channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "aVuSN7X8T5g5",
    "outputId": "781095e7-4605-435d-ae19-7098d8c50086"
   },
   "outputs": [],
   "source": [
    "def plot_img_channels(img, cmaps=['Reds', 'Greens', 'Blues']):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 3), sharey=True, sharex=True)\n",
    "    axs[0].imshow(img.astype(int))\n",
    "\n",
    "    for col, cmap in enumerate(cmaps):\n",
    "        axs[col + 1].imshow(img[...,col], cmap=cmap)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_img_channels(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transformation des couleurs\n",
    "\n",
    "D'abort on va transformer les couleurs de l'image.\n",
    "Les codages de couleur type luminance/chrominance donnent les meilleurs taux de compression car oeil humain assez sensible à la luminosité (luminance) mais peu à la teinte (chrominance) d'une image. (On fera donc un sous échantillonnage de couleurs sur ces couleurs là plutôt que sur RGB)\n",
    "\n",
    "![Perception](images_notebook/perception.png)\n",
    "\n",
    "La figure montre que la sensibilité de l'oeil humain est bien différente pour les couleurs rouge, vert et bleue constitutives de nos images. Ainsi le vert est-il le mieux perçu, puis vient le rouge, et enfin le bleu de maniere minoritaire. C'est donc \"moins grave\" de perdre l'information avec les couleurs type luminance/chrominacne. On passera donc d'une image codée en RGB à une image codée en fonction de sa luminance (Y), et de sa chrominance (Cb, Cr) (format YUV) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer de couleurs RGB à YUV consiste à faire un changement de base orthogonale (Rappel : la base de RGB est orthogonale)\n",
    "\n",
    "En principe, on a en quelque sorte :\n",
    "\n",
    "  $$  Y ≃ R + G + B \\\\\n",
    "    U ≃ B – Y \\\\\n",
    "    V ≃ R – Y$$\n",
    "    \n",
    "La matrice de changement de base est plus particulièrement définie ainsi : (Wikipédia + autres sources)\n",
    "\n",
    "![changement](changement_base.png)\n",
    "\n",
    "Ici, on utilise simplement une fonction du module Image de la librairie PIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de RGB_to_YCbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7uaOrpxX97v"
   },
   "outputs": [],
   "source": [
    "def RGB_to_YCbCr(img_rgb):\n",
    "    conv = np.array([[ 65.481, 128.553,  24.966], \n",
    "                     [-37.797, -74.203, 112.   ], \n",
    "                     [112.   , -93.786, -18.214]])\n",
    "    \n",
    "    img_ycbcr = np.dot(img_rgb.astype(float)/255, conv.T)\n",
    "    img_ycbcr[:,:,0] += 16\n",
    "    img_ycbcr[:,:,[1,2]] += 128\n",
    "    return img_ycbcr.astype(int)\n",
    "\n",
    "\n",
    "def YCbCr_to_RGB(img_ycbcr):\n",
    "    conv = np.array([[1,  0      , 1.402  ], \n",
    "                     [1, -0.34414, -.71414], \n",
    "                     [1,  1.772  , 0      ]])\n",
    "\n",
    "    img_rgb = img_ycbcr.astype(float)\n",
    "    img_rgb[:,:,[1,2]] -= 128\n",
    "    img_rgb = np.dot(img_rgb, conv.T)\n",
    "    \n",
    "    return np.clip(img_rgb, 0, 255).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "T2QdTiV4bSZN",
    "outputId": "daaa1e51-7edb-4256-b3ef-fe11118d5be8"
   },
   "outputs": [],
   "source": [
    "img_ycbcr = RGB_to_YCbCr(img)\n",
    "print(img_ycbcr.shape)\n",
    "plot_img_channels(img_ycbcr, ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "NEPxQ1zBic4i",
    "outputId": "877c564c-b0a5-42fc-fe51-7ca60df2d21b"
   },
   "outputs": [],
   "source": [
    "plot_img_channels(YCbCr_to_RGB(img_ycbcr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec la fonction du module Image de PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "u9YSKo9DCX9J",
    "outputId": "455d5045-db8f-48a0-efb7-e263fe219aa1"
   },
   "outputs": [],
   "source": [
    "img_yuv = Image.open('images_notebook/montagne.jpg').convert('YCbCr')\n",
    "\n",
    "plot_img_channels(np.array(img_yuv), ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sous échantillonnage des couleurs\n",
    "\n",
    "La deuxième étape de la compression est le sous échantillonnage des couleurs (Cb et Cr). On sépare les channels. On ne touche pas au channel Y mais on va rétrécir les image de U et V. Il y a plusieurs réglages possibles que l'on décrit avec la « notation J:a:b », définie ainsi, par bloc de 8x8 :\n",
    "- J est le nombre de pixels de Y conservés pour 4 pixels affichés, sur chaque ligne ;\n",
    "- a est le nombre de pixels de U conservés pour 4 pixels affichés, sur les lignes paires ;\n",
    "- b est le nombre de pixels de V conservés pour 4 pixels affichés, sur les lignes impaires.\n",
    "![subsampling](images_notebook/subsampling.png)\n",
    "\n",
    "Ainsi le sous échantillonnage de couleur le plus utilisé est le 4:2:0 (c'est à dire qu'on découpe l'image en bloc de 8x8). (Mais ce n'est pas le plus important, on peut prendre du 4:4:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Découpage de l'image en blocks\n",
    "\n",
    "\n",
    "En JPEG, on ne travaille pas sur une image entière : on travaille sur des blocs de 8x8 pixels (séparément en ce qui concerne l’intensité, le bleu et le rouge, donc).\n",
    "Si la taille d’une image n’est pas exactement un multiple de 8 dans un axe donné, et que\n",
    "la compression est forte, de légers défauts de compression pourraient apparaître. C’est un des soucis de JPEG.\n",
    "\n",
    "Chaque bloc de 8x8 est en suite envoyé pour être transformé par DCT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation des coefficients de [0;255] à [-128;127]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x0CkTlQxA08"
   },
   "outputs": [],
   "source": [
    "def shift_array(arr, shift=-128):\n",
    "    return arr + shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de transform_into_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQFBSjIhxwJJ"
   },
   "outputs": [],
   "source": [
    "def transform_into_blocks(img, block_size=8):\n",
    "    \"\"\"\n",
    "    Return a array of size (img.shape[0] // block_size, img.shape[1] // block_size, 3, block_size, block_size) or\n",
    "                         (3, img.shape[0] // block_size, img.shape[1] // block_size, block_size, block_size) (TBD)\n",
    "    First shape reads block from top to bottom, from left to right.\n",
    "    \"\"\"\n",
    "    nb_blocks_height = img.shape[0] // block_size\n",
    "    nb_blocks_width  = img.shape[1] // block_size\n",
    "\n",
    "    blocks = np.empty((nb_blocks_height, nb_blocks_width, 3, block_size, block_size), dtype=img.dtype)\n",
    "\n",
    "    for y in range(nb_blocks_height):\n",
    "        for x in range(nb_blocks_width):\n",
    "            for color in range(3):\n",
    "                blocks[y, x, color] = img[y * block_size:(y + 1) * block_size, \n",
    "                                          x * block_size:(x + 1) * block_size, \n",
    "                                          color]\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUdPmbLNzaWJ"
   },
   "outputs": [],
   "source": [
    "blocks = transform_into_blocks(img_ycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4yarE0I2PA2",
    "outputId": "a5921322-023b-4cbd-e339-24df9f8f1d5e"
   },
   "outputs": [],
   "source": [
    "blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xz2aaifB2g_S",
    "outputId": "040122e5-fe66-4a8c-b7d6-2de8295a02e5"
   },
   "outputs": [],
   "source": [
    "b1 = shift_array(blocks[0, 0, 1])\n",
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de transform_into_image (opération inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQFBSjIhxwJJ"
   },
   "outputs": [],
   "source": [
    "def transform_into_image(blocks, block_size=8):\n",
    "    \"\"\"\n",
    "    Return a array of size (img.shape[0] // block_size, img.shape[1] // block_size, 3, block_size, block_size) or\n",
    "                         (3, img.shape[0] // block_size, img.shape[1] // block_size, block_size, block_size) (TBD)\n",
    "    First shape reads block from top to bottom, from left to right.\n",
    "    \"\"\"\n",
    "    img_height = blocks.shape[0] * block_size\n",
    "    img_width  = blocks.shape[1] * block_size\n",
    "\n",
    "    img = np.empty((img_height, img_width, 3), dtype=blocks.dtype)\n",
    "\n",
    "    for i in range(blocks.shape[0]):\n",
    "        for j in range(blocks.shape[1]):\n",
    "            for color in range(3):\n",
    "                img[\n",
    "                    i * block_size : (i + 1) * block_size, \n",
    "                    j * block_size : (j + 1) * block_size, \n",
    "                    color,\n",
    "                ] = blocks[i, j, color]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_deblocked = transform_into_image(blocks)\n",
    "img_deblocked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_channels(img_deblocked, ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transformée en cosinus discret \n",
    "\n",
    "On fait une transformée DCT soit Discrete Cosine Transform. On applique cette transfo numérique à chaque bloc (variante de la transfo de fourier). Cette transfo décompose un bloc (considéré comme une fc num à deux variables) en une somme de fc cosinus oscillant à des freq différentes. Chaque bloc est ainsi décrit en une carte de freq et en amplitude plutôt qu'en pixels et coeff de couleur. (formule de la DCT dispo sur wiki) \n",
    "\n",
    "Le calcul d'une DCT est l'étape qui coûte le plus de temps et de ressources dans la compression JPEG. Mais elle peremt de séparer les basses et hautes freq de l'image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k--zJH177qtp",
    "outputId": "dd41da0e-8cc0-4129-8139-7e0ba7c5a177"
   },
   "outputs": [],
   "source": [
    "dct1 = fft.dctn(b1)\n",
    "dct1.shape, dct1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k--zJH177qtp",
    "outputId": "dd41da0e-8cc0-4129-8139-7e0ba7c5a177"
   },
   "outputs": [],
   "source": [
    "dct1 = fft.dctn(b1, norm='ortho')\n",
    "dct1.shape, dct1.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLhnSp-t2QS0"
   },
   "outputs": [],
   "source": [
    "def apply_dct(blocks):\n",
    "    return fft.dctn(blocks, axes=[-2, -1], norm ='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-6-7R1kGymR"
   },
   "outputs": [],
   "source": [
    "blocks_dct = apply_dct(shift_array(blocks))\n",
    "blocks_dct.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation DCT inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_idct(blocks):\n",
    "    return fft.idctn(blocks, axes=[-2,-1], norm='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_idct = apply_idct(blocks_dct)\n",
    "print(blocks_idct.shape)\n",
    "print(blocks_idct[0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocks = np.random.randn(16, 16)\n",
    "np.allclose(blocks, apply_idct(apply_dct(blocks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Quantification\n",
    "\n",
    "C'est à cette étape que l'on perd l'information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cate5Jtl7qLf"
   },
   "outputs": [],
   "source": [
    "quantization_matrix = np.array([[16, 11, 10, 16,  24,  40,  51,  61],\n",
    "                                [12, 12, 14, 19,  26,  58,  60,  55],\n",
    "                                [14, 13, 16, 24,  40,  57,  69,  56],\n",
    "                                [14, 17, 22, 29,  51,  87,  80,  62], \n",
    "                                [18, 22, 37, 56,  68, 109, 103,  77], \n",
    "                                [24, 35, 55, 64,  81, 104, 113,  92], \n",
    "                                [49, 64, 78, 87, 103, 121, 120, 101], \n",
    "                                [72, 92, 95, 98, 112, 100, 103,  99]], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYMrdYnPGYod"
   },
   "outputs": [],
   "source": [
    "def quantize(arr, quant_mat=quantization_matrix):\n",
    "    return np.round(np.divide(arr, quant_mat)).astype(int)\n",
    "\n",
    "def dequantize(arr, quant_mat=quantization_matrix):\n",
    "    return np.multiply(arr, quant_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EnI-6BGHAqk"
   },
   "outputs": [],
   "source": [
    "blocks_quant = quantize(blocks_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcKNP921HI4X",
    "outputId": "babda972-c743-476b-c4c5-0bd80c301a89"
   },
   "outputs": [],
   "source": [
    "blocks_quant[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC0AHtkLHKj_"
   },
   "outputs": [],
   "source": [
    "blocks_dequant = dequantize(blocks_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_deblocked = transform_into_image(apply_idct(blocks_dct))\n",
    "img_deblocked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_channels(YCbCr_to_RGB(shift_array(img_deblocked, 128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Codage RLE et Huffman \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC0AHtkLHKj_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www-ljk.imag.fr/membres/Valerie.Perrier/SiteWeb/node6.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "JPEG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
