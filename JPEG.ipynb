{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pjbenard/MPEG/blob/main/JPEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format de compression MPEG\n",
    "\n",
    "Notre projet consiste en l'implémentation du format compression MPEG. \n",
    "Le projet est divisé en deux parties : la compression JPEG et le \"flot optique\".\n",
    "\n",
    "## I. Compression JPEG\n",
    "\n",
    "La compression JPEG (Joint Photographic Experts Group) est un processus qui permet de réduire la taille d'une image \n",
    "\n",
    "Le processus de compression comporte six étapes principales :\n",
    "\n",
    "1. Transformation de couleurs\n",
    "2. Sous échantillonnage\n",
    "3. Découpage en blocs de pixels\n",
    "4. DCT\n",
    "5. Quantification\n",
    "6. Codage RLE et Huffman \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "5Z93Pvk9wKY9",
    "outputId": "53e27bd0-e0ae-4ad3-9ff0-dee295492141"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.fftpack as fft\n",
    "\n",
    "#from bokeh.plotting import figure, show\n",
    "#from bokeh.io import output_notebook\n",
    "#import holoviews as hv\n",
    "#hv.config.enable_colab_support = True\n",
    "#hv.extension('bokeh')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement de l'image. On a le choix entre l'image 'RGB_illumination.jpg' ou 'montagne.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2xUurXoT2YW"
   },
   "outputs": [],
   "source": [
    "\n",
    "#img_url = \"https://upload.wikimedia.org/wikipedia/commons/2/28/RGB_illumination.jpg\"\n",
    "#response = requests.get(img_url)\n",
    "#img = np.array(Image.open(BytesIO(response.content))).astype(int)\n",
    "\n",
    "img = np.array(Image.open('images_notebook/montagne.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u9TVdRwUiWq",
    "outputId": "9cfaf777-bdf5-4453-eb89-5c2c2beee1a1"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de l'image et des channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "aVuSN7X8T5g5",
    "outputId": "781095e7-4605-435d-ae19-7098d8c50086"
   },
   "outputs": [],
   "source": [
    "def plot_img_channels(img, cmaps=['Reds', 'Greens', 'Blues']):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 3), sharey=True, sharex=True)\n",
    "    axs[0].imshow(img.astype(int))\n",
    "\n",
    "    for col, cmap in enumerate(cmaps):\n",
    "        axs[col + 1].imshow(img[...,col], cmap=cmap)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_img_channels(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transformation des couleurs\n",
    "\n",
    "D'abort on va transformer les couleurs de l'image.\n",
    "Les codages de couleur type luminance/chrominance donnent les meilleurs taux de compression car oeil humain assez sensible à la luminosité (luminance) mais peu à la teinte (chrominance) d'une image. (On fera donc un sous échantillonnage de couleurs sur ces couleurs là plutôt que sur RGB)\n",
    "\n",
    "![Perception](images_notebook/perception.png)\n",
    "\n",
    "La figure montre que la sensibilité de l'oeil humain est bien différente pour les couleurs rouge, vert et bleue constitutives de nos images. Ainsi le vert est-il le mieux perçu, puis vient le rouge, et enfin le bleu de maniere minoritaire. C'est donc \"moins grave\" de perdre l'information avec les couleurs type luminance/chrominacne. On passera donc d'une image codée en RGB à une image codée en fonction de sa luminance (Y), et de sa chrominance (Cb, Cr) (format YUV) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer de couleurs RGB à YUV consiste à faire un changement de base orthogonale (Rappel : la base de RGB est orthogonale)\n",
    "\n",
    "En principe, on a en quelque sorte :\n",
    "\n",
    "  $$  Y ≃ R + G + B \\\\\n",
    "    U ≃ B – Y \\\\\n",
    "    V ≃ R – Y$$\n",
    "    \n",
    "La matrice de changement de base est plus particulièrement définie ainsi : (Wikipédia + autres sources)\n",
    "\n",
    "![changement](changement_base.png)\n",
    "\n",
    "Ici, on utilise simplement une fonction du module Image de la librairie PIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de RGB_to_YCbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7uaOrpxX97v"
   },
   "outputs": [],
   "source": [
    "def RGB_to_YCbCr(img_rgb):\n",
    "    # 1.3 s ± 10.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    conv = np.array([[ 65.481, 128.553,  24.966], \n",
    "                     [-37.797, -74.203, 112.   ], \n",
    "                     [112.   , -93.786, -18.214]])\n",
    "    \n",
    "    img_ycbcr = np.dot(img_rgb.astype(float)/255, conv.T)\n",
    "    img_ycbcr[:,:,0] += 16\n",
    "    img_ycbcr[:,:,[1,2]] += 128\n",
    "    return img_ycbcr.astype(int)\n",
    "\n",
    "def RGB_to_YCbCr_v2(img_rgb):\n",
    "    # 123 ms ± 1.31 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "    return np.array(Image.fromarray(img_rgb).convert('YCbCr'))\n",
    "    \n",
    "def YCbCr_to_RGB(img_ycbcr):\n",
    "    # 1.34 s ± 15.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    conv = np.array([[1,  0      , 1.402  ], \n",
    "                     [1, -0.34414, -.71414], \n",
    "                     [1,  1.772  , 0      ]])\n",
    "\n",
    "    img_rgb = img_ycbcr.astype(float)\n",
    "    img_rgb[:,:,[1,2]] -= 128\n",
    "    img_rgb = np.dot(img_rgb, conv.T)\n",
    "    \n",
    "    return np.clip(img_rgb, 0, 255).astype(int)\n",
    "\n",
    "def YCbCr_to_RGB_v2(img_ycbcr):\n",
    "    # 93.3 ms ± 618 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "    pre_img = np.clip(img_ycbcr, 0, 255).astype(np.uint8)\n",
    "    return np.array(Image.fromarray(pre_img, mode='YCbCr').convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "T2QdTiV4bSZN",
    "outputId": "daaa1e51-7edb-4256-b3ef-fe11118d5be8"
   },
   "outputs": [],
   "source": [
    "img_ycbcr = RGB_to_YCbCr(img)\n",
    "print(img_ycbcr.shape)\n",
    "plot_img_channels(img_ycbcr, ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "NEPxQ1zBic4i",
    "outputId": "877c564c-b0a5-42fc-fe51-7ca60df2d21b"
   },
   "outputs": [],
   "source": [
    "plot_img_channels(YCbCr_to_RGB(img_ycbcr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison avec la fonction du module Image de PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "u9YSKo9DCX9J",
    "outputId": "455d5045-db8f-48a0-efb7-e263fe219aa1"
   },
   "outputs": [],
   "source": [
    "img_yuv = RGB_to_YCbCr_v2(img)\n",
    "\n",
    "plot_img_channels(np.array(img_yuv), ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "u9YSKo9DCX9J",
    "outputId": "455d5045-db8f-48a0-efb7-e263fe219aa1"
   },
   "outputs": [],
   "source": [
    "img_rgb = YCbCr_to_RGB_v2(img_ycbcr)\n",
    "\n",
    "plot_img_channels(np.array(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sous échantillonnage des couleurs\n",
    "\n",
    "La deuxième étape de la compression est le sous échantillonnage des couleurs (Cb et Cr). On sépare les channels. On ne touche pas au channel Y mais on va rétrécir les image de U et V. Il y a plusieurs réglages possibles que l'on décrit avec la « notation J:a:b », définie ainsi, par bloc de 8x8 :\n",
    "- J est le nombre de pixels de Y conservés pour 4 pixels affichés, sur chaque ligne ;\n",
    "- a est le nombre de pixels de U conservés pour 4 pixels affichés, sur les lignes paires ;\n",
    "- b est le nombre de pixels de V conservés pour 4 pixels affichés, sur les lignes impaires.\n",
    "\n",
    "\n",
    "![subsampling](images_notebook/subsampling.png)\n",
    "\n",
    "Ainsi le sous échantillonnage de couleur le plus utilisé est le 4:2:0 (c'est à dire qu'on découpe l'image en bloc de 8x8). (Mais ce n'est pas le plus important, on peut prendre du 4:4:4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling_YCbCr(img_ycbcr):\n",
    "    img_sub = img_ycbcr.copy()\n",
    "    # Verticalement : tous les deuxièmes coefficients sont égaux au coefficient qu'il y a au dessus\n",
    "    img_sub[1::2,:,1] = img_sub[::2, :, 1] #channel Cb\n",
    "    img_sub[1::2,:,2] = img_sub[::2, :, 2] #channel Cr\n",
    "    #Horizontalement : tous les deuxièmes coeff sont égaux au coeff à leur gauche\n",
    "    img_sub[:, 1::2,1] = img_sub[:, ::2,1] \n",
    "    img_sub[:, 1::2,2] = img_sub[:, ::2,2] \n",
    "    return img_sub\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sub = subsampling_YCbCr(img_ycbcr)\n",
    "plot_img_channels(np.array(img_sub))\n",
    "plot_img_channels(np.array(img_ycbcr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img_sub[:,:,1] - img_ycbcr[:,:,1],return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ycbcr = np.copy(img_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Découpage de l'image en blocks\n",
    "\n",
    "\n",
    "En JPEG, on ne travaille pas sur une image entière : on travaille sur des blocs de 8x8 pixels (séparément en ce qui concerne l’intensité, le bleu et le rouge, donc).\n",
    "Si la taille d’une image n’est pas exactement un multiple de 8 dans un axe donné, et que\n",
    "la compression est forte, de légers défauts de compression pourraient apparaître. C’est un des soucis de JPEG.\n",
    "\n",
    "Chaque bloc de 8x8 est en suite envoyé pour être transformé par DCT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation des coefficients de [0;255] à [-128;127]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x0CkTlQxA08"
   },
   "outputs": [],
   "source": [
    "def shift_array(arr, shift=-128):\n",
    "    # 67.9 ms ± 834 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "    return arr + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shifted = shift_array(img_ycbcr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de transform_into_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQFBSjIhxwJJ"
   },
   "outputs": [],
   "source": [
    "def transform_into_blocks(img, block_size=8):\n",
    "    # 696 ms ± 14.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    \"\"\"\n",
    "    Return a array of size (img.shape[0] // block_size, img.shape[1] // block_size, 3, block_size, block_size) or\n",
    "                         (3, img.shape[0] // block_size, img.shape[1] // block_size, block_size, block_size) (TBD)\n",
    "    First shape reads block from top to bottom, from left to right.\n",
    "    \"\"\"\n",
    "    nb_blocks_height = img.shape[0] // block_size\n",
    "    nb_blocks_width  = img.shape[1] // block_size\n",
    "\n",
    "    blocks = np.empty((nb_blocks_height, nb_blocks_width, 3, block_size, block_size), dtype=img.dtype)\n",
    "\n",
    "    for y in range(nb_blocks_height):\n",
    "        for x in range(nb_blocks_width):\n",
    "            for color in range(3):\n",
    "                blocks[y, x, color] = img[y * block_size:(y + 1) * block_size, \n",
    "                                          x * block_size:(x + 1) * block_size, \n",
    "                                          color]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def transform_into_blocks_v2(img, block_size=8):\n",
    "    # 6.45 µs ± 113 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
    "    shape = img.shape\n",
    "    pre_blocks = np.reshape(img, (shape[0] // block_size, block_size, \n",
    "                                  shape[1] // block_size, block_size, \n",
    "                                  3))\n",
    "    \n",
    "    blocks = np.moveaxis(pre_blocks, [0, 1, 2, 3, 4], [0, 3, 1, 4, 2])\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = transform_into_blocks_v2(img_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4yarE0I2PA2",
    "outputId": "a5921322-023b-4cbd-e339-24df9f8f1d5e"
   },
   "outputs": [],
   "source": [
    "blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xz2aaifB2g_S",
    "outputId": "040122e5-fe66-4a8c-b7d6-2de8295a02e5"
   },
   "outputs": [],
   "source": [
    "b1 = shift_array(blocks[0, 0, 1])\n",
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de transform_into_image (opération inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQFBSjIhxwJJ"
   },
   "outputs": [],
   "source": [
    "def transform_into_image(blocks, block_size=8):\n",
    "    # 768 ms ± 39.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    \"\"\"\n",
    "    Return a array of size (img.shape[0] // block_size, img.shape[1] // block_size, 3, block_size, block_size) or\n",
    "                         (3, img.shape[0] // block_size, img.shape[1] // block_size, block_size, block_size) (TBD)\n",
    "    First shape reads block from top to bottom, from left to right.\n",
    "    \"\"\"\n",
    "    img_height = blocks.shape[0] * block_size\n",
    "    img_width  = blocks.shape[1] * block_size\n",
    "\n",
    "    img = np.empty((img_height, img_width, 3), dtype=blocks.dtype)\n",
    "\n",
    "    for i in range(blocks.shape[0]):\n",
    "        for j in range(blocks.shape[1]):\n",
    "            for color in range(3):\n",
    "                img[\n",
    "                    i * block_size : (i + 1) * block_size, \n",
    "                    j * block_size : (j + 1) * block_size, \n",
    "                    color,\n",
    "                ] = blocks[i, j, color]\n",
    "\n",
    "    return img\n",
    "\n",
    "def transform_into_image_v2(blocks, block_size=8):\n",
    "    # 6.53 µs ± 122 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
    "    pre_img = np.moveaxis(blocks, [0, 3, 1, 4, 2], [0, 1, 2, 3, 4])\n",
    "    \n",
    "    shape = pre_img.shape\n",
    "    img = np.reshape(pre_img, (shape[0] * shape[1], shape[2] * shape[3], 3))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_deblocked = transform_into_image_v2(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_deblocked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_channels(shift_array(img_deblocked, 128), ['gray'] * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transformée en cosinus discret \n",
    "\n",
    "On fait une transformée DCT soit Discrete Cosine Transform. On applique cette transfo numérique à chaque bloc (variante de la transfo de fourier). Cette transfo décompose un bloc (considéré comme une fc num à deux variables) en une somme de fc cosinus oscillant à des freq différentes. Chaque bloc est ainsi décrit en une carte de freq et en amplitude plutôt qu'en pixels et coeff de couleur. (formule de la DCT dispo sur wiki) \n",
    "\n",
    "Le calcul d'une DCT est l'étape qui coûte le plus de temps et de ressources dans la compression JPEG. Mais elle peremt de séparer les basses et hautes freq de l'image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k--zJH177qtp",
    "outputId": "dd41da0e-8cc0-4129-8139-7e0ba7c5a177"
   },
   "outputs": [],
   "source": [
    "dct1 = fft.dctn(b1)\n",
    "dct1.shape, dct1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k--zJH177qtp",
    "outputId": "dd41da0e-8cc0-4129-8139-7e0ba7c5a177"
   },
   "outputs": [],
   "source": [
    "dct1 = fft.dctn(b1, norm='ortho')\n",
    "dct1.shape, (dct1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLhnSp-t2QS0"
   },
   "outputs": [],
   "source": [
    "def apply_dct(blocks):\n",
    "    # 650 ms ± 18.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    return fft.dctn(blocks, axes=[-2, -1], norm ='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-6-7R1kGymR"
   },
   "outputs": [],
   "source": [
    "blocks_dct = apply_dct(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-6-7R1kGymR"
   },
   "outputs": [],
   "source": [
    "blocks_dct.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation DCT inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_idct(blocks):\n",
    "    # 631 ms ± 9.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    return np.round(fft.idctn(blocks, axes=[-2,-1], norm='ortho')).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_idct = apply_idct(blocks_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocks_idct.shape)\n",
    "print(blocks_idct[0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocks = np.random.randn(16, 16)\n",
    "np.allclose(blocks, apply_idct(apply_dct(blocks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Quantification\n",
    "\n",
    "C'est à cette étape que l'on perd l'information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cate5Jtl7qLf"
   },
   "outputs": [],
   "source": [
    "quantization_matrix = np.array([[16, 11, 10, 16,  24,  40,  51,  61],\n",
    "                                [12, 12, 14, 19,  26,  58,  60,  55],\n",
    "                                [14, 13, 16, 24,  40,  57,  69,  56],\n",
    "                                [14, 17, 22, 29,  51,  87,  80,  62], \n",
    "                                [18, 22, 37, 56,  68, 109, 103,  77], \n",
    "                                [24, 35, 55, 64,  81, 104, 113,  92], \n",
    "                                [49, 64, 78, 87, 103, 121, 120, 101], \n",
    "                                [72, 92, 95, 98, 112, 100, 103,  99]], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quant_matrix(Q=50):\n",
    "    if Q == 50:\n",
    "        return quantization_matrix\n",
    "    \n",
    "    elif Q > 50:\n",
    "        return np.round(50 * quantization_matrix / Q)\n",
    "    \n",
    "    else:\n",
    "        return np.round((100 - Q) * quantization_matrix / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYMrdYnPGYod"
   },
   "outputs": [],
   "source": [
    "def quantize(arr, quant_mat=get_quant_matrix(Q=50)):\n",
    "    # 311 ms ± 13.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    return np.round(np.divide(arr, quant_mat)).astype(int)\n",
    "\n",
    "def dequantize(arr, quant_mat=get_quant_matrix(Q=50)):\n",
    "    # 141 ms ± 5.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "    return np.multiply(arr, quant_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EnI-6BGHAqk"
   },
   "outputs": [],
   "source": [
    "blocks_quant = quantize(blocks_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcKNP921HI4X",
    "outputId": "babda972-c743-476b-c4c5-0bd80c301a89"
   },
   "outputs": [],
   "source": [
    "blocks_quant[0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC0AHtkLHKj_"
   },
   "outputs": [],
   "source": [
    "blocks_dequant = dequantize(blocks_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_deblocked = transform_into_image(blocks_idct)\n",
    "img_deblocked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_channels(YCbCr_to_RGB(shift_array(img_deblocked, 128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Codage RLE et Huffman \n",
    "\n",
    "\n",
    "On va calculer les entropies des DCT.\n",
    "L'entropie permet de mesurer le nombre de bit nécessaire pour coder l'information de la DCT.\n",
    "D'abord on doit aplatir les blocks 8x8 de l'image en vecteurs ligne, en prenant les coefficient en zigzag selon l'image suivante :\n",
    "\n",
    "![zigzag](images_notebook/zigzag.png)\n",
    "\n",
    "On va calculer l'entropie pour la DCT de chaque block aplatis selon le zigzag. \n",
    "- Il nous faut une fonction bloc_to_zigzag renvoyant une ligne de 64 ;\n",
    "- Les lignes zigzag s'arrêtent avec un signal \"end of block\" à définir, qui détermine à partir de quel coefficient le vecteur n'est rempli plus que de zéros\n",
    "- Une fonction qui prend toutes les lignes zigzag correspondant à tous les blocs de l'image, qui sélectionne le premier coeff de chaque ligne pour les mettre dans un vecteur \"premiers coeffs\" et qui sélectionne tous les autres vecteurs pour les mettre dans un vecteurs \"autres coeffs\".\n",
    "\n",
    "L'entropie (de Shannon) est définie par :\n",
    "\n",
    "$$E(\\pi) = - \\sum_i \\pi(\\alpha_i) log_2(\\pi(\\alpha_i)) $$\n",
    "\n",
    "Où $\\pi$ est la loi de probabilité d'apparition de chaque coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLE(block):\n",
    "#     block_rot = np.rot90(block, axes=(-2, -1))\n",
    "    block_rot = np.rot90(block)\n",
    "    flat_array = []\n",
    "    \n",
    "    n = block.shape[0]\n",
    "    for i in range(-n + 1, n):\n",
    "        flat_array += list(np.diagonal(block_rot, offset=i))[::int((-1)**i)]\n",
    "    \n",
    "    arr = np.array(flat_array, dtype=int)    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = RLE(blocks_quant[0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_EOB(ligne): #coupe le vecteur là où les 0 commencent et ajoute le EOB\n",
    "    size = ligne.size\n",
    "    count = 0\n",
    "    i = size-1\n",
    "    while (ligne[i]==0) and i > 0:\n",
    "            count +=1\n",
    "            i -= 1\n",
    "    new_ligne = ligne[:i+1].tolist()\n",
    "    new_ligne += ['EOB']\n",
    "    return new_ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC0AHtkLHKj_"
   },
   "outputs": [],
   "source": [
    "#test\n",
    "ligne_1 = np.array([1,2,3,0,0,4,1,2,0,0,0,0,0])\n",
    "ligne_2 = np.array([2,0,0,1,4,0,0,0,0,0,0,0,0])\n",
    "new_ligne_1 = put_EOB(ligne_1)\n",
    "new_ligne_2 = put_EOB(ligne_2)\n",
    "print(new_ligne_1)\n",
    "print(new_ligne_2)\n",
    "put_EOB(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_EOB(np.zeros(64, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ligne = [new_ligne_1,new_ligne_2]\n",
    "all_ligne[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet(all_ligne): #prend la liste des vecteurs lignes correspondant à tous les blocks de l'image\n",
    "    premiers_coeffs = []\n",
    "    autres_coeff = []\n",
    "    for i in range(len(all_ligne)):\n",
    "        premiers_coeffs += [all_ligne[i][0]]\n",
    "        autres_coeff += all_ligne[i][1:]\n",
    "    return premiers_coeffs, autres_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#print(all_ligne)\n",
    "#print(np.shape(all_ligne))\n",
    "premiers_coeffs, autres_coeffs = alphabet(all_ligne)\n",
    "print(premiers_coeffs)\n",
    "print(autres_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcule la proba d'apparition des coeffs\n",
    "#changer pour mettre des lignes à la place de img\n",
    "def distribution_coeff(img):  \n",
    "#     nb_pixel = img.size\n",
    "    nb_pixel = len(img)\n",
    "    coeffs,distribution = np.unique(img,return_counts= True)\n",
    "    distribution = distribution/nb_pixel\n",
    "    return coeffs, distribution, nb_pixel\n",
    "\n",
    "#calcule l'entropie\n",
    "def entropie(img):\n",
    "    E = 0\n",
    "    coeffs, distribution, nb_pixel = distribution_coeff(img)\n",
    "    #print(distribution)\n",
    "#     print(np.sum(distribution))\n",
    "    E = -np.sum(distribution*np.log2(distribution))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_dct(blocks):\n",
    "    shape = blocks.shape\n",
    "    rles = np.empty(shape[:-2] + (np.prod(shape[-2:]),))\n",
    "    after_EOB = []\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            for c in range(shape[2]):\n",
    "                after_EOB.append(put_EOB(RLE(blocks[i, j, c])))\n",
    "    \n",
    "    first_coeffs, other_coeffs = alphabet(after_EOB)\n",
    "    entropy_1 = entropie(first_coeffs)\n",
    "    entropy_2 = entropie(other_coeffs)\n",
    "    \n",
    "    return entropy_1, entropy_2, len(first_coeffs), len(other_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_dct(blocks_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. From image to jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_JPEG(img, Q=50):\n",
    "    # 5.91 s ± 21.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    \"\"\"Compress and return a JPEG image\"\"\"\n",
    "    T = get_quant_matrix(Q=Q)\n",
    "    \n",
    "    img = RGB_to_YCbCr(img)\n",
    "    img = shift_array(img, shift=-128)\n",
    "    \n",
    "    blocks = transform_into_blocks(img)\n",
    "    blocks = apply_dct(blocks)\n",
    "    blocks = quantize(blocks, T)\n",
    "    \n",
    "    blocks = dequantize(blocks, T)\n",
    "    blocks = apply_idct(blocks)\n",
    "    \n",
    "    img = transform_into_image(blocks)\n",
    "    img = shift_array(img, shift=128)\n",
    "    img = YCbCr_to_RGB(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def to_JPEG_v2(img, Q=50):\n",
    "    # 2.21 s ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    \"\"\"Compress and return a JPEG image\"\"\"\n",
    "    T = get_quant_matrix(Q=Q)\n",
    "    \n",
    "    img = RGB_to_YCbCr_v2(img)\n",
    "    img = shift_array(img, shift=-128)\n",
    "\n",
    "    blocks = transform_into_blocks_v2(img)\n",
    "    blocks = apply_dct(blocks)\n",
    "    blocks = quantize(blocks, T)\n",
    "    \n",
    "    blocks = dequantize(blocks, T)\n",
    "    blocks = apply_idct(blocks)\n",
    "    \n",
    "    img = transform_into_image_v2(blocks)\n",
    "    img = shift_array(img, shift=128)\n",
    "    img = YCbCr_to_RGB_v2(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(img_ref, img):\n",
    "    size = img_ref.size\n",
    "    return np.sum((img_ref - img)**2) / size\n",
    "\n",
    "def PSNR(img_ref, img):\n",
    "    return 20 * np.log10(255) - 10 * np.log10(MSE(img_ref, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_RAW = np.copy(img)\n",
    "plt.imshow(img_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_JPEG = to_JPEG_v2(img_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_JPEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR(img_RAW, img_JPEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Q in range(0, 101, 10):\n",
    "    img_JPEG = to_JPEG_v2(img_RAW, Q)\n",
    "    psnr = PSNR(img_RAW, img_JPEG)\n",
    "    print(f\"Facteur de qualite {Q:>3d}, PSNR = {psnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "JPEG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
